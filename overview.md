---
layout: page
title: "Overview"
permalink: /overview/
---

<!-- # Overview -->

Welcome to the AAAI 2026 Workshop! Building on the success of our inaugural event, this year’s workshop continues to bring together researchers and practitioners from neuroscience and artificial intelligence to deepen cross-disciplinary collaboration and insight.

Large Language Models (LLMs) have demonstrated remarkable \emph{capabilities} across a range of natural‑language and multi-modal tasks, including understanding, generation, and reasoning. 
However, raw capability alone is not sufficient for real-world deployment. 
The key barrier to adoption, particularly in  high‑risk domains such as healthcare, education or law, is __reliability__.

This burgeoning NeuroAI field is anchored by several key research areas, including but not limited to:


- **Neuro-inspired Computations:** This research focuses on developing hardware and algorithms inspired by the biological neuronal structure and function, such as spiking neural networks and Hebbian plasticity. Incorporating neuro-inspired mechanisms such as continual learning principles allows these systems to adapt and improve over time without requiring retraining from scratch, further enhancing their robustness and applicability in dynamic scenarios. For instance, recent advancements in neuromorphic computing, particularly the development of Intel’s Loihi chip, demonstrate the potential of spiking neural networks to improve the efficiency and capabilities of artificial systems. The Loihi chip mimics the brain’s neuronal architectures and synaptic plasticity mechanisms, enabling more efficient processing and learning in real-time environments.

- **Explainable AI in Neuroscience:** This research explores the integration of AI models with neuroscientific principles to enhance interpretability and explainability. For instance, the use of neural network architectures inspired by the human brain’s hierarchical processing can improve the interpretability of complex models by aligning them with known neural mechanisms. Techniques such as using neuro-symbolic AI, where symbolic reasoning is combined with neural networks, allow for the creation of models that can explain their reasoning in human-understandable terms. Additionally, methods like neural activity mapping and brain-inspired learning algorithms, such as those leveraging Hebbian learning principles, offer ways to trace AI decision paths back to their origins in the model’s structure.

- **NeuroAI for Safety, Alignment, and Intentional Control:** Bridging neuroscience with AI safety offers promising new frameworks for alignment, interpretability, and robustness. NeuroAI can inform mechanisms for value learning, behavioral priors, and grounded cognition that promote safer AI behavior. Recent work highlights how neuroscience can inspire safe AI by emulating brain architectures, leveraging neural data for interpretability, and scaling cognitive models~\cite{mineault2024neuroai}. Ongoing efforts like [Intentions in AI](https://ai-intentions.org/events/june-2025-workshop/) emphasize the importance of understanding goals, intentions, and internal drives in biological systems—drawing from neuroscience and consciousness research—to differentiate, track, and steer these processes in AI systems. Initiatives like [NeuroAI Safety](https://neuroaisafety.com/) explore how principles such as bounded rationality, attention, and uncertainty minimization can provide robust inductive biases for building AI that is not only intelligent but also predictable, steerable, and aligned with human values.

- **Neuroadaptive Interfaces for Human-AI Co-Cognition:** This area explores next-generation Brain-Computer Interfaces (BCIs) that combine neural decoding and adaptive AI to enable richer human-AI interaction. Beyond traditional motor or attention decoding, recent advances target high-level cognitive states, like goals, intentions, and semantics, via neuro-symbolic approaches. Neuroadaptive systems further personalize BCIs using large language models (LLMs) and co-adaptive feedback, as seen in ChatBCI and NeuroAssist. By merging structured reasoning with flexible adaptation, these hybrid systems support interpretable, compositional, and evolving collaboration across applications in neuroprosthetics, assistive cognition, and thought-to-language translation. 
    

- **Neuro-Cognitive Models for Reasoning and Decision-Making:** This area explores how neuroscience and cognitive science can inform AI systems with human-like reasoning, decision-making, and creativity. It focuses on brain-inspired models using distributed representations, adaptive learning, and context-sensitive architectures to build more flexible, robust cognition. In parallel, it emphasizes rigorous evaluation across cognitive domains—language, reasoning, and creativity—using benchmarks like logic puzzles, translation tasks, and storytelling. Together, these efforts aim to advance general, interpretable, and human-aligned AI.

- **Self-supervised Systems in NeuroAI:** This area explores how emerging paradigms like predictive coding, active inference, and self-supervised learning—rooted in biological intelligence—can be integrated into artificial systems. These approaches enable AI to learn from unstructured data without labels, mirroring how brains adapt in real-world settings. Predictive coding suggests the brain continuously refines sensory predictions by minimizing errors, while active inference extends this to action, forming a unified perception-action cycle~\cite{friston2016active}. These principles underpin advances in visual processing, autonomous behavior, and intuitive AI.
    

    

Our workshop aims to explore the intersections among these research areas and provide a platform for researchers to navigate the links between artificial and natural intelligence (see [Call for Papers](https://neuroai-workshop.github.io/call-for-papers/)). Accordingly, we hope to use the workshop as a vehicle for delving deeper into this interdisciplinary landscape; evaluate progress toward a unified (computational) framework for natural intelligence and investigate its potential for artificial intelligence. Through discussions about the current research trajectories in neuroscience and AI, we seek to identify fundamental gaps and challenges, paving the way for novel insights and future directions.


For further information and should you have any inquiries, please contact: [neuroai.neurips2024@gmail.com](mailto:neuroai.neurips2024@gmail.com)



